{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Customer Feedback Analysis Project\n",
       "\n",
       "## Business Impact: Product Improvement through Customer Sentiment Analysis\n",
       "\n",
       "In this project, we'll analyze Amazon product reviews to help businesses understand:\n",
       "1. Overall customer satisfaction\n",
       "2. Key product features that customers love/hate\n",
       "3. Common pain points and improvement areas\n",
       "4. Sentiment trends over time\n",
       "\n",
       "This analysis can directly impact business decisions by:\n",
       "- Identifying priority areas for product improvement\n",
       "- Understanding customer preferences\n",
       "- Tracking the impact of product changes\n",
       "- Improving customer satisfaction"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import pandas as pd\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "from nltk.tokenize import word_tokenize\n",
       "from nltk.corpus import stopwords\n",
       "from nltk.sentiment import SentimentIntensityAnalyzer\n",
       "from collections import Counter\n",
       "import re\n",
       "from datetime import datetime\n",
       "import warnings\n",
       "import gzip\n",
       "import json\n",
       "import requests\n",
       "from io import BytesIO\n",
       "warnings.filterwarnings('ignore')\n",
       "\n",
       "# Set up plotting style\n",
       "plt.style.use('seaborn')\n",
       "sns.set_palette('husl')\n",
       "\n",
       "# Initialize sentiment analyzer\n",
       "sia = SentimentIntensityAnalyzer()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Data Collection and Preparation\n",
       "\n",
       "We'll use the Amazon Product Reviews dataset, which contains millions of reviews across different product categories. For this project, we'll focus on a specific product category to keep the analysis manageable."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "def load_amazon_reviews(category='Electronics', max_reviews=1000):\n",
       "    \"\"\"Load Amazon reviews for a specific category\"\"\"\n",
       "    # URL for the Amazon review dataset\n",
       "    url = f\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_{category}_5.json.gz\"\n",
       "    \n",
       "    try:\n",
       "        # Download the file\n",
       "        response = requests.get(url)\n",
       "        response.raise_for_status()  # Raise an exception for bad status codes\n",
       "        \n",
       "        # Read the gzipped file\n",
       "        with gzip.GzipFile(fileobj=BytesIO(response.content)) as f:\n",
       "            # Read and parse the JSON lines\n",
       "            reviews = []\n",
       "            for i, line in enumerate(f):\n",
       "                if i >= max_reviews:\n",
       "                    break\n",
       "                review = json.loads(line)\n",
       "                reviews.append({\n",
       "                    'review_id': review.get('reviewerID', ''),\n",
       "                    'product': review.get('asin', ''),\n",
       "                    'review_text': review.get('reviewText', ''),\n",
       "                    'rating': review.get('overall', 0),\n",
       "                    'date': review.get('reviewTime', ''),\n",
       "                    'category': category\n",
       "                })\n",
       "        \n",
       "        return pd.DataFrame(reviews)\n",
       "    \n",
       "    except requests.exceptions.RequestException as e:\n",
       "        print(f\"Error downloading data: {e}\")\n",
       "        print(\"\\nUsing sample data instead...\")\n",
       "        \n",
       "        # Fallback to sample data if download fails\n",
       "        return pd.DataFrame([\n",
       "            {\n",
       "                'review_id': 'A1B2C3',\n",
       "                'product': 'Sample Product',\n",
       "                'review_text': 'This is a great product with amazing features. The battery life is excellent!',\n",
       "                'rating': 5,\n",
       "                'date': '2024-01-15',\n",
       "                'category': 'Electronics'\n",
       "            },\n",
       "            {\n",
       "                'review_id': 'D4E5F6',\n",
       "                'product': 'Sample Product',\n",
       "                'review_text': 'Good product but the camera quality could be better.',\n",
       "                'rating': 3,\n",
       "                'date': '2024-01-20',\n",
       "                'category': 'Electronics'\n",
       "            }\n",
       "        ])\n",
       "\n",
       "# Load the data\n",
       "print(\"Loading Amazon reviews...\")\n",
       "df = load_amazon_reviews(category='Electronics', max_reviews=1000)\n",
       "\n",
       "# Display basic information about the dataset\n",
       "print(\"\\nDataset Information:\")\n",
       "print(f\"Number of reviews: {len(df)}\")\n",
       "print(f\"\\nSample reviews:\")\n",
       "print(df[['review_text', 'rating']].head())\n",
       "\n",
       "# Basic statistics\n",
       "print(\"\\nRating Distribution:\")\n",
       "print(df['rating'].value_counts().sort_index())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Data Cleaning and Preprocessing\n",
       "\n",
       "Let's clean and preprocess the review data to prepare it for analysis:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "def clean_review_text(text):\n",
       "    \"\"\"Clean and preprocess review text\"\"\"\n",
       "    if not isinstance(text, str):\n",
       "        return \"\"\n",
       "    \n",
       "    # Convert to lowercase\n",
       "    text = text.lower()\n",
       "    \n",
       "    # Remove special characters and numbers\n",
       "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
       "    \n",
       "    # Remove extra whitespace\n",
       "    text = ' '.join(text.split())\n",
       "    \n",
       "    return text\n",
       "\n",
       "# Clean the review text\n",
       "df['cleaned_text'] = df['review_text'].apply(clean_review_text)\n",
       "\n",
       "# Convert date strings to datetime objects\n",
       "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
       "\n",
       "# Remove rows with missing values\n",
       "df = df.dropna(subset=['review_text', 'rating', 'date'])\n",
       "\n",
       "print(\"\\nCleaned Dataset Information:\")\n",
       "print(f\"Number of reviews after cleaning: {len(df)}\")\n",
       "print(\"\\nSample of cleaned reviews:\")\n",
       "print(df[['cleaned_text', 'rating']].head())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Text Preprocessing Exercise\n",
       "\n",
       "Let's create a more comprehensive preprocessing function that includes:\n",
       "1. Removing stopwords\n",
       "2. Lemmatization\n",
       "3. Handling contractions\n",
       "4. Removing URLs and email addresses"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# TODO: Implement the advanced preprocessing function\n",
       "def advanced_preprocess(text):\n",
       "    \"\"\"Implement advanced text preprocessing\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "# Test your implementation\n",
       "sample_text = \"The product's battery life is amazing! Check it out at www.example.com or email us at test@example.com\"\n",
       "processed_text = advanced_preprocess(sample_text)\n",
       "print(\"Processed text:\", processed_text)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Sentiment Analysis Exercise\n",
       "\n",
       "Create a function that:\n",
       "1. Analyzes sentiment of reviews\n",
       "2. Categorizes reviews as Positive, Negative, or Neutral\n",
       "3. Calculates confidence scores"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# TODO: Implement the sentiment analysis function\n",
       "def analyze_sentiment_with_confidence(text):\n",
       "    \"\"\"Analyze sentiment with confidence scores\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "# Test your implementation\n",
       "test_reviews = [\n",
       "    \"This product is absolutely amazing! Best purchase ever.\",\n",
       "    \"The quality is okay, nothing special.\",\n",
       "    \"Terrible product, would not recommend.\"\n",
       "]\n",
       "\n",
       "for review in test_reviews:\n",
       "    result = analyze_sentiment_with_confidence(review)\n",
       "    print(f\"\\nReview: {review}\")\n",
       "    print(f\"Analysis: {result}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Feature Extraction Exercise\n",
       "\n",
       "Create a function that:\n",
       "1. Identifies product features mentioned in reviews\n",
       "2. Extracts sentiment for each feature\n",
       "3. Calculates feature importance scores"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# TODO: Implement the feature extraction function\n",
       "def extract_features_with_sentiment(text):\n",
       "    \"\"\"Extract features and their sentiment\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "# Test your implementation\n",
       "test_review = \"The battery life is excellent, but the camera quality needs improvement. The screen is beautiful though.\"\n",
       "features = extract_features_with_sentiment(test_review)\n",
       "print(\"Extracted features with sentiment:\")\n",
       "print(features)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Visualization Exercise\n",
       "\n",
       "Create functions to visualize:\n",
       "1. Sentiment distribution\n",
       "2. Feature importance\n",
       "3. Sentiment trends over time"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# TODO: Implement visualization functions\n",
       "def plot_sentiment_distribution(sentiments):\n",
       "    \"\"\"Plot sentiment distribution\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "def plot_feature_importance(features):\n",
       "    \"\"\"Plot feature importance\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "def plot_sentiment_trends(dates, sentiments):\n",
       "    \"\"\"Plot sentiment trends over time\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "# Test your implementations\n",
       "print(\"Implement and test your visualization functions here\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Business Insights Exercise\n",
       "\n",
       "Create a function that generates business insights by:\n",
       "1. Identifying top positive and negative features\n",
       "2. Calculating improvement priorities\n",
       "3. Generating actionable recommendations"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# TODO: Implement the business insights function\n",
       "def generate_business_insights(reviews_data):\n",
       "    \"\"\"Generate business insights from review data\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "# Test your implementation\n",
       "sample_data = {\n",
       "    'reviews': [\n",
       "        {'text': 'Great battery life but poor camera', 'rating': 4},\n",
       "        {'text': 'Amazing screen quality', 'rating': 5},\n",
       "        {'text': 'Battery drains too fast', 'rating': 2}\n",
       "    ]\n",
       "}\n",
       "\n",
       "insights = generate_business_insights(sample_data)\n",
       "print(\"Generated insights:\")\n",
       "print(insights)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 7. Main Project Exercise\n",
       "\n",
       "Now it's your turn! Create a complete customer feedback analysis system that:\n",
       "\n",
       "1. Loads and processes real Amazon review data\n",
       "2. Implements all the functions from previous exercises\n",
       "3. Generates comprehensive business insights\n",
       "4. Creates visualizations for key findings\n",
       "5. Produces a detailed analysis report"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# TODO: Implement the complete analysis system\n",
       "\n",
       "def analyze_customer_feedback(category='Electronics', max_reviews=1000):\n",
       "    \"\"\"Complete customer feedback analysis system\"\"\"\n",
       "    # Your code here\n",
       "    pass\n",
       "\n",
       "# Run the analysis\n",
       "results = analyze_customer_feedback()\n",
       "print(\"Analysis complete! Check the results above.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Solutions\n",
       "\n",
       "Here are the solutions to all exercises:\n",
       "\n",
       "### Exercise 2: Advanced Preprocessing\n",
       "```python\n",
       "def advanced_preprocess(text):\n",
       "    # Convert to lowercase\n",
       "    text = text.lower()\n",
       "    \n",
       "    # Remove URLs\n",
       "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
       "    \n",
       "    # Remove email addresses\n",
       "    text = re.sub(r'\\S+@\\S+', '', text)\n",
       "    \n",
       "    # Handle contractions\n",
       "    contractions = {\n",
       "        \"'s\": \" is\",\n",
       "        \"'re\": \" are\",\n",
       "        \"'t\": \" not\",\n",
       "        \"'d\": \" would\",\n",
       "        \"'ll\": \" will\",\n",
       "        \"'ve\": \" have\"\n",
       "    }\n",
       "    for contraction, expansion in contractions.items():\n",
       "        text = text.replace(contraction, expansion)\n",
       "    \n",
       "    # Remove special characters and numbers\n",
       "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
       "    \n",
       "    # Tokenize\n",
       "    tokens = word_tokenize(text)\n",
       "    \n",
       "    # Remove stopwords\n",
       "    stop_words = set(stopwords.words('english'))\n",
       "    tokens = [token for token in tokens if token not in stop_words]\n",
       "    \n",
       "    # Lemmatize\n",
       "    lemmatizer = WordNetLemmatizer()\n",
       "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
       "    \n",
       "    return ' '.join(tokens)\n",
       "```\n",
       "\n",
       "### Exercise 3: Sentiment Analysis\n",
       "```python\n",
       "def analyze_sentiment_with_confidence(text):\n",
       "    scores = sia.polarity_scores(text)\n",
       "    \n",
       "    # Determine sentiment category\n",
       "    if scores['compound'] >= 0.05:\n",
       "        sentiment = 'Positive'\n",
       "    elif scores['compound'] <= -0.05:\n",
       "        sentiment = 'Negative'\n",
       "    else:\n",
       "        sentiment = 'Neutral'\n",
       "    \n",
       "    # Calculate confidence\n",
       "    confidence = abs(scores['compound'])\n",
       "    \n",
       "    return {\n",
       "        'sentiment': sentiment,\n",
       "        'confidence': confidence,\n",
       "        'scores': scores\n",
       "    }\n",
       "```\n",
       "\n",
       "### Exercise 4: Feature Extraction\n",
       "```python\n",
       "def extract_features_with_sentiment(text):\n",
       "    # Define feature keywords\n",
       "    features = {\n",
       "        'battery': ['battery', 'life', 'charge'],\n",
       "        'camera': ['camera', 'photo', 'picture'],\n",
       "        'screen': ['screen', 'display', 'resolution'],\n",
       "        'performance': ['performance', 'speed', 'fast', 'slow'],\n",
       "        'software': ['software', 'app', 'interface']\n",
       "    }\n",
       "    \n",
       "    # Preprocess text\n",
       "    tokens = advanced_preprocess(text).split()\n",
       "    \n",
       "    # Extract features and their sentiment\n",
       "    feature_sentiments = {}\n",
       "    for feature, keywords in features.items():\n",
       "        if any(keyword in tokens for keyword in keywords):\n",
       "            # Get sentiment for the feature\n",
       "            feature_text = ' '.join([word for word in tokens if any(k in word for k in keywords)])\n",
       "            sentiment = analyze_sentiment_with_confidence(feature_text)\n",
       "            feature_sentiments[feature] = sentiment\n",
       "    \n",
       "    return feature_sentiments\n",
       "```\n",
       "\n",
       "### Exercise 5: Visualizations\n",
       "```python\n",
       "def plot_sentiment_distribution(sentiments):\n",
       "    plt.figure(figsize=(10, 6))\n",
       "    sns.histplot(sentiments, bins=20)\n",
       "    plt.title('Distribution of Review Sentiments')\n",
       "    plt.xlabel('Sentiment Score')\n",
       "    plt.ylabel('Number of Reviews')\n",
       "    plt.show()\n",
       "\n",
       "def plot_feature_importance(features):\n",
       "    plt.figure(figsize=(12, 6))\n",
       "    sns.barplot(x=list(features.keys()), y=[f['confidence'] for f in features.values()])\n",
       "    plt.title('Feature Importance')\n",
       "    plt.xticks(rotation=45)\n",
       "    plt.show()\n",
       "\n",
       "def plot_sentiment_trends(dates, sentiments):\n",
       "    plt.figure(figsize=(12, 6))\n",
       "    plt.plot(dates, sentiments)\n",
       "    plt.title('Sentiment Trends Over Time')\n",
       "    plt.xlabel('Date')\n",
       "    plt.ylabel('Average Sentiment')\n",
       "    plt.xticks(rotation=45)\n",
       "    plt.show()\n",
       "```\n",
       "\n",
       "### Exercise 6: Business Insights\n",
       "```python\n",
       "def generate_business_insights(reviews_data):\n",
       "    insights = []\n",
       "    \n",
       "    # Analyze overall sentiment\n",
       "    sentiments = [analyze_sentiment_with_confidence(review['text']) for review in reviews_data['reviews']]\n",
       "    avg_sentiment = np.mean([s['scores']['compound'] for s in sentiments])\n",
       "    insights.append(f\"Overall customer satisfaction: {avg_sentiment:.2f}\")\n",
       "    \n",
       "    # Analyze features\n",
       "    feature_sentiments = {}\n",
       "    for review in reviews_data['reviews']:\n",
       "        features = extract_features_with_sentiment(review['text'])\n",
       "        for feature, sentiment in features.items():\n",
       "            if feature not in feature_sentiments:\n",
       "                feature_sentiments[feature] = []\n",
       "            feature_sentiments[feature].append(sentiment['scores']['compound'])\n",
       "    \n",
       "    # Generate feature insights\n",
       "    for feature, sentiments in feature_sentiments.items():\n",
       "        avg_sent = np.mean(sentiments)\n",
       "        insights.append(f\"{feature.capitalize()}: {avg_sent:.2f}\")\n",
       "    \n",
       "    # Generate recommendations\n",
       "    insights.append(\"\\nRecommendations:\")\n",
       "    for feature, sentiments in feature_sentiments.items():\n",
       "        avg_sent = np.mean(sentiments)\n",
       "        if avg_sent < 0:\n",
       "            insights.append(f\"- Improve {feature} quality\")\n",
       "        elif avg_sent > 0.5:\n",
       "            insights.append(f\"- Highlight {feature} in marketing\")\n",
       "    \n",
       "    return '\\n'.join(insights)\n",
       "```\n",
       "\n",
       "### Exercise 7: Complete Analysis System\n",
       "```python\n",
       "def analyze_customer_feedback(category='Electronics', max_reviews=1000):\n",
       "    # Load data\n",
       "    df = load_amazon_reviews(category, max_reviews)\n",
       "    \n",
       "    # Preprocess\n",
       "    df['processed_text'] = df['review_text'].apply(advanced_preprocess)\n",
       "    \n",
       "    # Analyze sentiment\n",
       "    sentiment_scores = df['review_text'].apply(analyze_sentiment_with_confidence)\n",
       "    df['sentiment'] = sentiment_scores.apply(lambda x: x['sentiment'])\n",
       "    df['confidence'] = sentiment_scores.apply(lambda x: x['confidence'])\n",
       "    \n",
       "    # Extract features\n",
       "    df['features'] = df['processed_text'].apply(extract_features_with_sentiment)\n",
       "    \n",
       "    # Generate visualizations\n",
       "    plot_sentiment_distribution(df['confidence'])\n",
       "    \n",
       "    # Generate insights\n",
       "    insights = generate_business_insights({'reviews': df.to_dict('records')})\n",
       "    \n",
       "    return {\n",
       "        'dataframe': df,\n",
       "        'insights': insights\n",
       "    }\n",
       "```"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }